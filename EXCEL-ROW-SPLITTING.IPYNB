{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **SPLITTING OF EXCEL FILE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Project Overview: Automated Data Reconciliation and Processing Efficiency Enhancement**\n",
    "\n",
    "In the final stages of the 2023 end-of-year reconciliation, a challenge emerged concerning the processing of unsuccessful SMS data. This data, comprising approximately three thousand rows, required loading onto a platform with a strict limit of 500 rows per Excel file. To address this, my team manually split the data into manageable segments. Recognizing the potential for similar challenges in the future, we proactively decided to implement an automated solution using Python scripts.\n",
    "\n",
    "To expedite this process and ensure a swift resolution, we harnessed the capabilities of ChatGPT through a carefully crafted prompt. This innovative approach allowed us to leverage AI alongside our human programming expertise, facilitating the creation of a robust and scalable solution.\n",
    "\n",
    "\n",
    "\n",
    "By incorporating the synergy of AI and human programming, we not only addressed an immediate challenge but also laid the foundation for an automated and templated solution. This strategic integration not only saved valuable time during the reconciliation process but also significantly enhanced overall productivity. The project exemplifies our commitment to leveraging cutting-edge technologies for efficiency gains and process optimization in data analysis workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PROMPT ENGINEERING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt engineering refers to the practice of crafting specific and well-formulated prompts when interacting with natural language processing (NLP) models or language models. In the context of working with models like GPT (Generative Pre-trained Transformer), including GPT-3, prompt engineering involves designing input queries or instructions that elicit desired responses from the model.\n",
    "\n",
    "The goal of prompt engineering is to guide the model to produce outputs that align with the user's intentions or expectations. Well-designed prompts take advantage of the model's capabilities and quirks, influencing it to generate accurate, contextually relevant, and coherent responses.\n",
    "\n",
    "Below is the prompt crafted by the team."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an excel file called \"SMS\" in this \"Excel file pathe was given\" directory. The excel has about three thousand rows.\n",
    "\n",
    "Help with codes that splits the rows into 500 each into different excel workbooks till all the total rows are exhausted. Exclude column headers in each split. And name the excel workbooks as \"DEC 23 UNSUCCESSFUL SMS\" with the number of split done. Eg. 'DEC 23 UNSUCCESSFUL SMS 1', 'DEC 23 UNSUCCESSFUL SMS 2' and so on. \n",
    "\n",
    "Keep the original SMS file and create a different excel workbooks that stores the various splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PROMPT RESPONSE (CODE)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **os** module provides a way of interacting with the operating system. It can be used for tasks such as reading or writing to the file system, working with directories, and executing system commands.\n",
    "\n",
    "The **pandas** library is a powerful data manipulation and analysis library for Python. It provides data structures like DataFrames, which are convenient for handling and analyzing structured data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loading the needed library\n",
    "import os\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. `file_path = r\"EXCEL-FILE-PATH\\SMS.xlsx\"`: This line defines the file path to the Excel file named \"SMS.xlsx\". The `r` prefix is used to create a raw string, which is helpful when specifying file paths to avoid issues with escape characters.\n",
    "\n",
    "2. `original_df = pd.read_excel(file_path, header=None)`: This line reads the Excel file specified by the `file_path` into a pandas DataFrame named `original_df`. The function `pd.read_excel` is used for reading Excel files. The `header=None` argument indicates that there is no header row in the Excel file, and pandas should not treat the first row as column names.\n",
    "\n",
    "After executing this code, the data from the Excel file will be loaded into the DataFrame `original_df`, allowing further analysis and manipulation of the data using pandas functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the original Excel file\n",
    "file_path = r\"EXCEL-FILE-PATH\\SMS.xlsx\"\n",
    "original_df = pd.read_excel(file_path, header=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. `rows_per_split = 500`: This line defines a variable `rows_per_split` and sets it to 500. It specifies the desired number of rows for each split of the DataFrame.\n",
    "\n",
    "2. `num_splits = (len(original_df) - 1) // rows_per_split + 1`: This line calculates the total number of splits needed. Here's the breakdown:\n",
    "\n",
    "   - `len(original_df)`: Returns the total number of rows in the `original_df` DataFrame.\n",
    "   - `(len(original_df) - 1)`: Subtracts 1 from the total number of rows. This is done to ensure that there is no leftover row after splitting.\n",
    "   - `// rows_per_split`: Performs integer division by `rows_per_split` to determine how many full splits of size `rows_per_split` can be made.\n",
    "   - `+ 1`: Adds 1 to account for any remaining rows that didn't make a full split.\n",
    "\n",
    "The result is stored in the variable `num_splits`, representing the total number of splits required to process the entire DataFrame in chunks of 500 rows each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Specify the number of rows per split\n",
    "rows_per_split = 500\n",
    "\n",
    "# Calculate the total number of splits\n",
    "num_splits = (len(original_df) - 1) // rows_per_split + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is responsible for creating a directory to store the split files. Let's break down the key components:\n",
    "\n",
    "\n",
    "1. `output_directory = r\"EXCEL-FILE-PATH\\Splits\"`: This line defines the variable `output_directory` and assigns it the path where the split files will be stored. The `r` prefix indicates a raw string, which is often used for file paths to handle backslashes without escaping.\n",
    "\n",
    "2. `os.makedirs(output_directory, exist_ok=True)`: The `os.makedirs` function is used to create the specified directory. The `exist_ok=True` parameter ensures that the function does not raise an error if the directory already exists. If the directory doesn't exist, it will be created.\n",
    "\n",
    "In summary, this code ensures that there is a directory (`Splits`) in the specified path to accommodate the split files. If the directory already exists, it will not raise an error, and if it doesn't exist, it will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create a directory to store the split files\n",
    "output_directory = r\"EXCEL-FILE-PATH\\Splits\"\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is responsible for splitting the original DataFrame into smaller chunks and saving each chunk as a new Excel file. Let's break down the key components:\n",
    "\n",
    "\n",
    "1. `for i in range(num_splits)`: This loop iterates over the range of splits calculated earlier (`num_splits`), creating a subset of the DataFrame for each iteration.\n",
    "\n",
    "2. `start_idx = i * rows_per_split` and `end_idx = (i + 1) * rows_per_split`: These lines calculate the start and end indices for each split.\n",
    "\n",
    "3. `df_split = original_df.iloc[start_idx:end_idx]`: This line creates a subset of the original DataFrame (`original_df`) using the calculated indices.\n",
    "\n",
    "4. `output_file_path = os.path.join(output_directory, f\"DEC 23 UNSUCCESSFUL SMS {i + 1}.xlsx\")`: This line generates the file path for the output Excel file, including the iteration number in the filename.\n",
    "\n",
    "5. `with pd.ExcelWriter(output_file_path, engine='xlsxwriter') as writer:`: This context manager sets up a mechanism for writing to the Excel file using the `xlsxwriter` engine.\n",
    "\n",
    "6. `df_split.to_excel(writer, sheet_name=\"Sheet1\", index=False, header=False)`: This line writes the subset DataFrame to the Excel file without including row and column headers.\n",
    "\n",
    "7. `print(\"Splitting complete.\")`: After the loop, a message is printed to indicate that the splitting process is complete.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting complete.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Split the DataFrame and save each split to a new Excel file\n",
    "for i in range(num_splits):\n",
    "    start_idx = i * rows_per_split\n",
    "    end_idx = (i + 1) * rows_per_split\n",
    "    df_split = original_df.iloc[start_idx:end_idx]\n",
    "\n",
    "    # Create a new workbook for each split\n",
    "    output_file_path = os.path.join(output_directory, f\"DEC 23 UNSUCCESSFUL SMS {i + 1}.xlsx\")\n",
    "    with pd.ExcelWriter(output_file_path, engine='xlsxwriter') as writer:\n",
    "        df_split.to_excel(writer, sheet_name=\"Sheet1\", index=False, header=False)\n",
    "\n",
    "print(\"Splitting complete.\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
